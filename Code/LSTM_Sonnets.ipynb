{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG_vd17u-hQf"
      },
      "source": [
        "# Miniproject 3: Poem Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vutgGS2_-hQh"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjLtzVpd-hQi",
        "outputId": "71f69d76-bd8d-4c96-ac8b-2eed62ca45f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading...\n",
            "Complete\n",
            "Start downloading...\n",
            "Complete\n",
            "Start downloading...\n",
            "Complete\n",
            "Start downloading...\n",
            "Complete\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url_dict = {\n",
        "    'shakespeare.txt': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/shakespeare.txt',\n",
        "    'spenser.txt': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/spenser.txt',\n",
        "    'syllable_dict.txt' : 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/Syllable_dictionary.txt',\n",
        "    'about_syllable_dict.docx' : 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/syllable_dict_explanation.docx'\n",
        "}\n",
        "\n",
        "def download_file(file_path):\n",
        "    url = url_dict[file_path]\n",
        "    print('Start downloading...')\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(file_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=1024 * 1024 * 1024):\n",
        "                f.write(chunk)\n",
        "    print('Complete')\n",
        "\n",
        "download_file('shakespeare.txt')\n",
        "download_file('spenser.txt')\n",
        "download_file('syllable_dict.txt')\n",
        "download_file('about_syllable_dict.docx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3fmyMeX-hQq"
      },
      "source": [
        "## RNN Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_sonnets(text):\n",
        "    sonnets = re.split(r'(?:^|\\n)\\s*\\d+\\s*\\n', text.strip())\n",
        "\n",
        "    sonnets = [sonnet.strip() for sonnet in sonnets[1:] if sonnet.strip()]\n",
        "\n",
        "    return sonnets\n",
        "\n",
        "with open('shakespeare.txt', 'r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "sonnets = parse_sonnets(raw_text)"
      ],
      "metadata": {
        "id": "TLONZE_9KkpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, sonnets, seq_length=40, stride=3):\n",
        "        self.seq_length = seq_length\n",
        "        self.stride = stride\n",
        "\n",
        "        # Use the sonnets list directly\n",
        "        self.sonnets = [sonnet.strip() for sonnet in sonnets if sonnet.strip()]\n",
        "\n",
        "        # Create a mapping of characters to indices and vice versa\n",
        "        self.char_to_idx = {char: idx for idx, char in enumerate(sorted(set(\"\".join(self.sonnets))))}\n",
        "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
        "        self.vocab_size = len(self.char_to_idx)\n",
        "\n",
        "        self.sequences = []\n",
        "        for sonnet in self.sonnets:\n",
        "            for i in range(0, len(sonnet) - seq_length, stride):\n",
        "                sequence = sonnet[i:i + seq_length]\n",
        "                target = sonnet[i + 1:i + seq_length + 1]\n",
        "                self.sequences.append((sequence, target))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence, target = self.sequences[idx]\n",
        "        x = torch.tensor([self.char_to_idx[c] for c in sequence], dtype=torch.long)\n",
        "        y = torch.tensor([self.char_to_idx[c] for c in target], dtype=torch.long)\n",
        "        return x, y\n",
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=150, num_layers=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        return (torch.zeros(1, batch_size, self.hidden_dim, device=device),\n",
        "                torch.zeros(1, batch_size, self.hidden_dim, device=device))\n",
        "\n",
        "def train_model(model, train_loader, num_epochs, device, learning_rate=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        hidden = None\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, hidden = model(inputs)\n",
        "            if hidden is not None:\n",
        "                hidden = tuple(h.detach() for h in hidden)\n",
        "            output = output.view(-1, model.vocab_size)\n",
        "            targets = targets.view(-1)\n",
        "            loss = criterion(output, targets)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': total_loss/(batch_idx+1)})\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "def generate_text(model, dataset, seed_text, length=500, temperature=1.0, device='cpu'):\n",
        "    model.eval()\n",
        "    current_text = seed_text\n",
        "    generated_text = seed_text\n",
        "\n",
        "    # Track number of lines generated\n",
        "    line_count = 0\n",
        "    line_length = dataset.seq_length  # You can define how long each line should be (sequence length)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while line_count < 14:  # Limit to 14 lines for a sonnet\n",
        "            if len(current_text) > line_length:\n",
        "                current_text = current_text[-line_length:]  # Keep the last `line_length` characters\n",
        "\n",
        "            x = torch.tensor([dataset.char_to_idx[c] for c in current_text], dtype=torch.long)\n",
        "            x = x.unsqueeze(0).to(device)\n",
        "            output, _ = model(x)\n",
        "            output = output[0, -1, :] / temperature\n",
        "            probs = torch.softmax(output, dim=0)\n",
        "            next_char_idx = torch.multinomial(probs, 1).item()\n",
        "            next_char = dataset.idx_to_char[next_char_idx]\n",
        "\n",
        "            # Add the generated character to the text\n",
        "            generated_text += next_char\n",
        "            current_text = current_text[1:] + next_char\n",
        "\n",
        "            # Track if we've completed a line (based on length)\n",
        "            if next_char == '\\n':\n",
        "                line_count += 1\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "seq_length = 40\n",
        "dataset = CharacterDataset(sonnets, seq_length=seq_length)\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CharLSTM(vocab_size=dataset.vocab_size).to(device)\n",
        "\n",
        "print(\"\\nTraining LSTM model...\")\n",
        "train_model(model, train_loader, num_epochs=30, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpOr3gThPf8I",
        "outputId": "2c2723ba-2db0-4059-f0fc-f8d82ca44743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 459/459 [00:07<00:00, 61.08it/s, loss=2.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 2.5988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 459/459 [00:07<00:00, 62.00it/s, loss=1.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 1.9911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 459/459 [00:07<00:00, 57.76it/s, loss=1.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 1.8117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 459/459 [00:07<00:00, 59.04it/s, loss=1.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 1.7092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 459/459 [00:07<00:00, 61.76it/s, loss=1.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Average Loss: 1.6346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 459/459 [00:07<00:00, 62.48it/s, loss=1.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Average Loss: 1.5758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 459/459 [00:07<00:00, 58.95it/s, loss=1.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Average Loss: 1.5247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 459/459 [00:07<00:00, 59.67it/s, loss=1.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Average Loss: 1.4816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 459/459 [00:07<00:00, 62.44it/s, loss=1.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Average Loss: 1.4424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 459/459 [00:07<00:00, 58.96it/s, loss=1.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Average Loss: 1.4074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 459/459 [00:07<00:00, 61.56it/s, loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Average Loss: 1.3755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 459/459 [00:07<00:00, 61.42it/s, loss=1.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Average Loss: 1.3456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 459/459 [00:07<00:00, 61.40it/s, loss=1.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Average Loss: 1.3186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 459/459 [00:07<00:00, 59.98it/s, loss=1.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Average Loss: 1.2940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 459/459 [00:07<00:00, 61.26it/s, loss=1.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Average Loss: 1.2698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 459/459 [00:07<00:00, 61.30it/s, loss=1.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Average Loss: 1.2485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 459/459 [00:07<00:00, 61.79it/s, loss=1.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Average Loss: 1.2295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 459/459 [00:08<00:00, 54.57it/s, loss=1.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Average Loss: 1.2116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 459/459 [00:07<00:00, 61.28it/s, loss=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Average Loss: 1.1935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 459/459 [00:08<00:00, 51.51it/s, loss=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Average Loss: 1.1779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 459/459 [00:07<00:00, 61.34it/s, loss=1.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Average Loss: 1.1622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 459/459 [00:07<00:00, 58.92it/s, loss=1.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Average Loss: 1.1483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 459/459 [00:07<00:00, 61.08it/s, loss=1.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Average Loss: 1.1352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 459/459 [00:07<00:00, 59.31it/s, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Average Loss: 1.1225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 459/459 [00:08<00:00, 56.44it/s, loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Average Loss: 1.1105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 459/459 [00:07<00:00, 57.64it/s, loss=1.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Average Loss: 1.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 459/459 [00:07<00:00, 58.06it/s, loss=1.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Average Loss: 1.0885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 459/459 [00:07<00:00, 61.69it/s, loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Average Loss: 1.0787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 459/459 [00:07<00:00, 61.13it/s, loss=1.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Average Loss: 1.0687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 459/459 [00:07<00:00, 60.81it/s, loss=1.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Average Loss: 1.0603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Shall I compare thee to a summer's day?\"\n",
        "temps = [0.25, 0.75, 1.5, 2]\n",
        "for temp in temps:\n",
        "  generated_poem = generate_text(model, dataset, seed_text, length=500, temperature=temp, device=device)\n",
        "  print(f\"\\nTemperature: {temp}\")\n",
        "  print(generated_poem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_x2gdbOQPuS",
        "outputId": "4030560b-465f-4564-bf20-561c52971ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature: 0.25\n",
            "Shall I compare thee to a summer's day?\n",
            "Thou art more love thee that thou mayst call,\n",
            "Whilst I (my self a worther than thy self dost light?\n",
            "Be thou art born to the lives and speak of the star\n",
            "To the world will be thy self a worthless song,\n",
            "Darkening thee wit the world will be thy self a same,\n",
            "And by a part of the sun is so show,\n",
            "  And they thou mayst be so true, no shall excuse my love excuse the strong,\n",
            "When I behold is so strong such a sad say,\n",
            "  And they thou art comemonned and the most of self-doing cross;\n",
            "To say they have I seen the fairest once side,\n",
            "And by their pride back to thee and stay\n",
            "That bear the lovely on thee,\n",
            "  That in their stars in the stars in thee thy self alone,\n",
            "\n",
            "\n",
            "Temperature: 0.75\n",
            "Shall I compare thee to a summer's day?\n",
            "Thou art more nature's changing stars thy worth the treasure? O shall my self art,\n",
            "And I am thy beauty decay,\n",
            "And sor my grace they with that doth with thy self alone.\n",
            "  But what in war as thou being mourners, seem'st the beauty of thy will,\n",
            "And that shall lif's night by that which he all,\n",
            "Dost for one respect,\n",
            "  For thy self deceivest by their wills be.\n",
            "  And this in their rhyme barren hate,\n",
            "Under shall statues thy amade, becomes a poet's day,\n",
            "And therefore mayst be praise shall cover\n",
            "One in me, I do return of such shape,\n",
            "Thereou art be west are so from thee,\n",
            "By mountient that I may be so belong,\n",
            "\n",
            "\n",
            "Temperature: 1.5\n",
            "Shall I compare thee to a summer's day?\n",
            "Thence is endroliggor lalmailing beauty his speak,\n",
            "With Aprion is roin and doth decake?\n",
            "Destruining heact dost the charter and his general keep, yito-datients are centaps a breast,\n",
            "Hunt on me. against the carlet to compounds every wone?\n",
            "Why so base doth life, and but in userd'ation mine.\n",
            "Seal in the worst what tender anlens' kingle,\n",
            "Aming by anjuning hide your self\n",
            "That stay'st my fleasure old necessary:\n",
            "More than at best of me's unthles, death,\n",
            "  Suns am bright, when woman's face of all that from tender self:\n",
            "  Let some sed on prizing part,\n",
            "  More speek) they find all external wlail,\n",
            "The pictul estifns to be hate, desired may, I vicious calllal.\n",
            "\n",
            "\n",
            "Temperature: 2\n",
            "Shall I compare thee to a summer's day?\n",
            "So ha live? I hall-mbsift, let gofded sipput:\n",
            "Lait feigureless, and still heart\n",
            "Rentactify old it grew,\n",
            " Landed know. sing mointed I sooce,\n",
            "Whilst h) it that pen) digs fire,\n",
            "Whelese's leedring it back all mere on,\n",
            "The gentle lost, this nunted befomellly two cancek;\n",
            ".ntle load pleas, of that whichret-bry:\n",
            "Duthest perficuling eir state outlors bear\n",
            "Laining like you hind lascivry, tull mutuars (thy lvess?\n",
            "Or better contented klight-not?\n",
            "Thy naturl'nn age, w) or keep remumagl'st\n",
            "And all those pent, sinq and hy may see tie?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpidEuFq-hQr"
      },
      "source": [
        "## Additional Goal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erG7Qq2A-hQr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a_nFdFZ-hQs"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLGodA3o-hQs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}